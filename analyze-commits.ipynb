{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a9e2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(path):\n",
    "  csv = pd.read_csv(path)\n",
    "  \n",
    "  # Ensure commit message is a string.\n",
    "  csv['message'] = csv['message'].astype(str)\n",
    "  \n",
    "  return csv\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "commits_per_language = dict(map(lambda path: (Path(path).stem, read_csv(path)), glob('results/csv/*.csv')))\n",
    "all_commits = reduce(lambda a, b: pd.concat([a, b], ignore_index=True), commits_per_language.values())\n",
    "\n",
    "stop = perf_counter()\n",
    "print(f'Loading files took {stop - start:0.3f} seconds.')\n",
    "\n",
    "all_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages = [commit['message'] for (index, commit) in all_commits.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed14a3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "gitmoji_mappings = {\n",
    "  ':memo:':             'docs',        # Documentation\n",
    "  ':zap:':              'perf',        # Performance\n",
    "  ':fire:':             'remove',      # Removal\n",
    "  ':sparkles:':         'feat',        # Feature\n",
    "  ':bug:':              'fix',         # Bug Fix\n",
    "  ':lipstick:':         'ui',          # UI\n",
    "  ':wrench:':           'config',      # Configuration\n",
    "  ':hammer:':           'development', # Development Scripts\n",
    "  ':art:':              'refactor',    # Improve Code Structure/Format\n",
    "  ':white_check_mark:': 'test',        # Tests\n",
    "  ':chore:':            'chore',       # Chore\n",
    "  ':up:':               'update',      # Update\n",
    "  ':arrow_up:':         'deps',        # Dependency Update\n",
    "  ':arrow_down:':       'deps',        # Dependency Downgrade\n",
    "  ':bulb:':             'docs',        # Update Source Code Comments\n",
    "  ':rocket:':           'deploy',      # Deployment\n",
    "  ':pencil2:':          'typo',        # Fix Typo\n",
    "  ':green_heart:':      'ci',          # Fix CI\n",
    "  ':construction:':     'wip',         # Work In Progress\n",
    "  ':recycle:':          'refactor',    # Refactor Code\n",
    "}\n",
    "\n",
    "tag_mappings = {\n",
    "  'bug':           'fix',\n",
    "  'bugfix':        'fix',\n",
    "  'testing':       'test',\n",
    "  'tests':         'test',\n",
    "  'tst':           'test',\n",
    "  'documentation': 'docs',\n",
    "  'doc':           'docs',\n",
    "  'changelog':     'docs',\n",
    "  'feature':       'feat',\n",
    "  'gui':           'ui',\n",
    "}\n",
    "\n",
    "def message_to_tag(message):\n",
    "  message = message.lower()\n",
    "  \n",
    "  # Extract “Conventional Commits”.\n",
    "  match = re.match(r'^([^(\\s:]+)(?:\\([^)]+\\))?!?:\\s*(.*)$', message)\n",
    "  if match:\n",
    "    tag = match[1]\n",
    "    message = match[2]\n",
    "    return (message, tag_mappings.get(tag) or tag)        \n",
    "      \n",
    "  # Extract “Gitmoji Commits”.\n",
    "  match = re.match(r'^(:[a-z0-9_]+:)\\s*(.*)$', message)\n",
    "  if match:\n",
    "    tag = match[1]\n",
    "    message = match[2]\n",
    "    return (message, gitmoji_mappings.get(tag) or tag)\n",
    "  \n",
    "  return (message, None)\n",
    "\n",
    "known_tags = set([\n",
    "  'build',\n",
    "  'chore',\n",
    "  'ci',\n",
    "  'deps',\n",
    "  'docs',\n",
    "  'feat',\n",
    "  'fix',\n",
    "  'perf',\n",
    "  'refactor',\n",
    "  'style',\n",
    "  'test',\n",
    "  'examples',\n",
    "])\n",
    "\n",
    "def message_to_known_tag(message):\n",
    "  message, tag = message_to_tag(message)\n",
    "  return (message, tag) if tag in known_tags else (message, None)\n",
    "\n",
    "tags = [tag for (message, tag) in map(message_to_tag, all_messages) if tag]\n",
    "\n",
    "tag_freq_dist = nltk.FreqDist(tags)\n",
    "tag_freq_dist.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "wanted_tags = [tag for tag in tags if tag in known_tags]\n",
    "\n",
    "tagged_commits = all_commits.copy()\n",
    "tagged_commits[['message', 'tag']] = tagged_commits['message'].apply(message_to_known_tag).apply(pd.Series)\n",
    "tagged_commits['message'] = tagged_commits['message'].apply(helpers.tokenize)\n",
    "tagged_commits.dropna(subset=['tag'], inplace=True)\n",
    "tagged_commits.reset_index(inplace=True)\n",
    "tagged_commits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "tagged_commits['label'] = label_encoder.fit_transform(tagged_commits['tag'])\n",
    "target_data = tagged_commits['label']\n",
    "tagged_commits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer() \n",
    "\n",
    "source_data = vect.fit_transform([\" \".join(message) for message in tagged_commits[\"message\"]])\n",
    "source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5d277",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "print(\"Splits:\", kf.get_n_splits(source_data))\n",
    "\n",
    "results = list(map(helpers.test, enumerate((index, source_data, target_data) for index in kf.split(source_data))))\n",
    "\n",
    "# with multiprocessing.Pool() as p:\n",
    "#  results = p.map(helpers.test, enumerate(kf.split(source_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15412bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy, f1_micro, f1_macro = np.mean(results, axis=0)\n",
    "\n",
    "print(\"Total Accuracy:\", accuracy)\n",
    "print(\"Total F1 micro:\", f1_micro)\n",
    "print(\"Total F1 macro:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77505f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import mr4mp\n",
    "\n",
    "pool = mr4mp.pool()\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "messages = [commit['message'] for (index, commit) in all_commits.iterrows()]\n",
    "stop = perf_counter()\n",
    "print(f'Creating list of messages took {stop - start:0.3f} seconds.')\n",
    "\n",
    "all_words = pool.mapreduce(helpers.tokenize, helpers.reduce_list, messages)\n",
    "stop = perf_counter()\n",
    "print(f'Tokenizing messages took {stop - start:0.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "freq_dist = nltk.FreqDist(all_words)\n",
    "\n",
    "m = 100\n",
    "most_common_words = set(dist[0] for dist in freq_dist.most_common(m))\n",
    "\n",
    "n = 100\n",
    "least_common_words = set(dist[0] for dist in freq_dist.most_common()[:-n-1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13a339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "least_common_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
