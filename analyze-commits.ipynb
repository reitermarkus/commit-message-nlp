{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a9e2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from time import sleep, perf_counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(path):\n",
    "  csv = pd.read_csv(path)\n",
    "  \n",
    "  # Ensure commit message is a string.\n",
    "  csv['message'] = csv['message'].astype(str)  \n",
    "  \n",
    "  return csv\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "commits_per_language = dict(map(lambda path: (Path(path).stem, read_csv(path)), glob('results/csv/*.csv')))\n",
    "all_commits = reduce(lambda a, b: pd.concat([a, b], ignore_index=True), commits_per_language.values())\n",
    "\n",
    "stop = perf_counter()\n",
    "print(f'Loading files took {stop - start:0.3f} seconds.')\n",
    "\n",
    "all_commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77505f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import mr4mp\n",
    "import helpers\n",
    "\n",
    "pool = mr4mp.pool()\n",
    "\n",
    "start = perf_counter()\n",
    "\n",
    "messages = [commit['message'] for (index, commit) in all_commits.iterrows()]\n",
    "stop = perf_counter()\n",
    "print(f'Creating list of messages took {stop - start:0.3f} seconds.')\n",
    "\n",
    "all_words = pool.mapreduce(helpers.tokenize, helpers.reduce_list, messages)\n",
    "stop = perf_counter()\n",
    "print(f'Tokenizing messages took {stop - start:0.3f} seconds.')\n",
    "\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccdfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "freq_dist = nltk.FreqDist(all_words)\n",
    "\n",
    "m = 100\n",
    "most_common_words = set(dist[0] for dist in freq_dist.most_common(m))\n",
    "\n",
    "n = 100\n",
    "least_common_words = set(dist[0] for dist in freq_dist.most_common()[:-n-1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13a339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "least_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1b341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
