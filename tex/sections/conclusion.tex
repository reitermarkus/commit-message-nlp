\section{Conclusion}
\label{sec:conclusion}

In this paper we presented an approach to construct a new dataset containing
commit messages of various repositories from many popular languages on GitHub.
In order to complete the project, we first had to scrape repositories, followed
by tagging commits and finally using the data to test and train a logistic
regression model. While most of the development process was straightforward and
as expected, some problems arose especially during the scraping part. API limits
are among the worst offenders in that regard. Fortunately we could prevail by
circumventing those barriers and find a different approach.

The results are interesting because of the differentiation between per-author
limit and no per-author limit. Naturally, once such a limit is in place the
amount of high quality commit messages decreases and best practices are not
followed in some cases. The report reflects that notion as the amount of
tagged commits decreased from about 35000 to about 25000 from a total of
1000000 commit messages once the limit was in place. The actual tag distribution
however followed roughly the same trajectory, lead by “fix” which is
not really surprising considering the fact that most commits are bug fixes.
Looking at the accuracy, F1 micro and F2 macro numbers, the contrast between
author limits can be seen in \autoref{fig:unlimited_commits} and \autoref{fig:limited_commits}
as well, as all the metrics are lower with the limit. Besides that fact, the
numbers are not unusual and about what we expected initially.

For future work the criteria could be changed. Focusing on repositories with
tagged commits and in general fewer small repositories could yield better
results. Furthermore, focusing on specific languages with a different
importance metric when choosing codebases, could also be interesting.
